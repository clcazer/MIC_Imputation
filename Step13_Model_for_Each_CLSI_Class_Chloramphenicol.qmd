# Chloramphenicol (CHL)

-   CLSI Class: Phenicols

## Filtering CHL isolates

##### Filtering CHL isolates into a separate dataframe to build RF

```{r}
CHL.RF.df <- NARMSCattleCombined_ordinal      
#checking if there are any NAs for variable in this dataframe   
(sum(is.na(CHL.RF.df[38]))/nrow(CHL.RF.df)*100) #returns 0
```

##### Check dependent variable (what predicting) is a factor in dataframe

```{r}
is.factor(CHL.RF.df$CHL) #returns TRUE 
```

##### Make all categorical variables in dataframe factors

```{r}
CategoricalVar<-c("STATE", "Year", "Month", "RAISING_CLAIM", "COUNTRY_OF_ORIGIN", "SOURCE", "SOURCE_SPECIES_INFO", "BRAND", "BRAND_NAME", "dataset_source", "HOST_SPECIES")    

CHL.RF.df[CategoricalVar]<-lapply(CHL.RF.df[CategoricalVar], factor)    
remove(CategoricalVar)   

#Resist.Genes variables (ex: Aminoglycoside.Resist.Genes), GENOTYPE were not included in model because majority of isolates do not have this information
```

## Missing Data Analysis for Antimicrobials

##### For each AM, what percentage of total number of isolates were tested against that AM

```{r}
MissingDataAnalysis_AMs(CHL.RF.df)
```

| **AM_Name** | **Percent_of_Isolates_Tested** |
|:------------|:-------------------------------|

|         |                  |
|---------|------------------|
| **AMC** | **100.00000000** |
| **AXO** | **100.00000000** |
| CHL     | 100.00000000     |
| **CIP** | **100.00000000** |
| **COT** | **100.00000000** |
| **FOX** | **100.00000000** |
| **GEN** | **100.00000000** |
| **NAL** | **100.00000000** |
| **TET** | **100.00000000** |
| **AMP** | **99.99146248**  |
| Str     | 99.98292496      |
| **FIS** | **94.86894903**  |
| AZI     | 78.04149236      |
| MER     | 51.72031077      |
| TIO     | 48.27968923      |
| KAN     | 32.20353453      |
| AMI     | 21.95850764      |
| CEP     | 5.13105097       |
| SMX     | 5.13105097       |
| ATM     | 0.05122513       |
| CAZ     | 0.05122513       |
| CTX     | 0.05122513       |
| FEP     | 0.05122513       |
| IMI     | 0.05122513       |
| PTZ     | 0.05122513       |
| APR     | 0.00000000       |
| CLI     | 0.00000000       |
| DAP     | 0.00000000       |
| DOX     | 0.00000000       |
| ERY     | 0.00000000       |
| FFN     | 0.00000000       |
| LIN     | 0.00000000       |
| LZD     | 0.00000000       |
| NIT     | 0.00000000       |
| PEN     | 0.00000000       |
| QDA     | 0.00000000       |
| TEL     | 0.00000000       |
| TGC     | 0.00000000       |
| TYL     | 0.00000000       |
| VAN     | 0.00000000       |

8 AM predictors are measured on 90% or greater of the isolates in the dataframe and so will be used as possible predictor variables

## Missing Data Analysis for Categorical Variables

##### For each categorical variable, what percentage of total number of isolates were tested against that variable

```{r}
MissingDataAnalysis_CategoricalVar(CHL.RF.df)
```

| **Variable Name** | **Percent_of_Isolates_Tested** |
|:------------------|:-------------------------------|

|                     |                |
|---------------------|----------------|
| **Year**            | **100.000000** |
| **dataset_source**  | **100.000000** |
| **SOURCE**          | **100.000000** |
| **HOST_SPECIES**    | **100.000000** |
| ACQUISITION_DATE    | 99.846325      |
| Month               | 88.201144      |
| SOURCE_SPECIES_INFO | 77.332878      |
| STATE               | 39.084778      |
| GROWTH              | 39.084778      |
| MEAT_TYPE           | 39.084778      |
| BRAND_NAME          | 36.062495      |
| BRAND               | 35.652694      |
| CUTS                | 20.037565      |
| COUNTRY_OF_ORIGIN   | 11.585418      |
| GENOTYPE            | 9.997439       |
| RAISING_CLAIM       | 4.482199       |

##### Checking Levels for Categorical Variables with 90% plus data:

```{r}
levels(CHL.RF.df$Year)
```

```{r}
levels(CHL.RF.df$dataset_source)
```

```{r}
levels(CHL.RF.df$SOURCE)
```

```{r}
levels(CHL.RF.df$HOST_SPECIES)
```

Possible Categorical Variable Predictor Variables: (have enough data filled in and have unique levels)

-   SOURCE

-   Year

## Create 70% Training and 30% Testing Data Split

```{r}
#set a random seed and shuffle data frame to get random sample of data in both the testing and training set  
set.seed(1234)  
CHL.RF.df<-CHL.RF.df[sample(1:nrow(CHL.RF.df)), ]
```

```{r}
#use 70% data for training and other 30% for testing    
# get the number 70/30 training test split  
numberOfTrainingSamples <- round(length(CHL.RF.df$CHL) * .7)    

# training data  
set.seed(1234)  
trainCHLRF <- CHL.RF.df[1:numberOfTrainingSamples,] 
trainCHLRF_labels <- CHL.RF.df$CHL[1:numberOfTrainingSamples]   

# testing data 
set.seed(1234) 
testCHLRF <- CHL.RF.df[-(1:numberOfTrainingSamples),]  
testCHLRF_labels <- CHL.RF.df$CHL[-(1:numberOfTrainingSamples)]   

remove(numberOfTrainingSamples)
```

## Balancing CHL Levels

##### Original Training Data Distribution

```{r}
table(trainCHLRF$CHL)
```

##### Try Oversampling to Balance all levels:

```{r}
#Oversample to balance all MIC categories  
set.seed(71)
over.CHL.RF.df<- RandOverClassif(CHL~., trainCHLRF, "balance")  #"balance" tries to balance all existing classes    

table(over.CHL.RF.df$CHL) #This oversamples other categories so that there are 4267 rows (number of observations of majority category) for each
```

##### Try a mix of undersampling and oversampling

```{r}
#Undersample MIC category 4 and 8 
set.seed(71)
C.perc= list("4"=0.09, "8"=0.07) 
under_over.CHL.RF.df<- RandUnderClassif(CHL~., trainCHLRF, C.perc)  
table(under_over.CHL.RF.df$CHL) #first undersample

#Oversample MIC category 16 
set.seed(71)
C.perc= list("16"=2) 
under_over.CHL.RF.df<- RandOverClassif(CHL~., under_over.CHL.RF.df, C.perc )  
table(under_over.CHL.RF.df$CHL) #then oversample
```

## Random Forest:

### Original

##### Build RF using Training Data:

```{r}
set.seed(71)  
RFCHL<-randomForest(CHL~Year+SOURCE+AMC+AXO+CIP+COT+FOX+GEN+NAL+TET+AMP+FIS, data=trainCHLRF, na.action=na.exclude, ntree=500, importance=TRUE)  
RFCHL  
#37.27% OOB estimate of error rate  
#ntree=500  
#mtry=3 (number of variables tried at each split)  
```

##### Tune Predictor Variables:

```{r}
##check the order of the predictors in the model's prediction power  
pre.or <- sort(RFCHL$importance[,3], decreasing = TRUE) #adding [,3] gives the power with the title of the variable 
pre.or  
remove(pre.or)   
#return a plot showing the importance of a predictor to the model by accuracy and Gini score  
varImpPlot(RFCHL, main="")
```

-   Strongest predictors

    -   Ampicillin (penicillin)
    -   Nalidixic acid (Quinolone)
    -   Sulfisoxazole (FIS)

##### Prediction on Training Data

```{r}
trainRFCHL_prediction<- predict(RFCHL,trainCHLRF)   
trainconMatCHLRF<-confusionMatrix(trainRFCHL_prediction, trainCHLRF$CHL)
trainconMatCHLRF$table  
paste('Accuracy =', round(trainconMatCHLRF$overall["Accuracy"],2)) #returns accuracy
trainconMatCHLRF$overall #also gives accuracy in output in scientific notation  
#accuracy is now 75% on training data
```

##### Prediction on Test Data:

```{r}
testRFCHL_prediction<-predict(RFCHL,testCHLRF) 
testConMatCHLRF<-confusionMatrix(testRFCHL_prediction,testCHLRF$CHL) 
paste('Accuracy =', round(testConMatCHLRF$overall["Accuracy"],2)) #returns accuracy 
#accuracy is 63% on test data   
CHL_RF_ConMat<-testConMatCHLRF$table  #saves just the confusion matrix as an object for future analysis 
  
testConMatCHLRF
```

##### Exact Accuracy:

```{r}
ConMat_Accuracy(CHL_RF_ConMat)
```

| **MIC isolate category** | **Proportion_of_Isolates** |
|:-------------------------|:---------------------------|

|     |           |
|-----|-----------|
| 4   | 0.5853994 |
| 8   | 0.6864256 |
| 16  | 0.0000000 |
| 32  | 0.5890411 |

##### Balanced Accuracy:

```{r}
CHL_RF_AccStats<-testConMatCHLRF$byClass      
Balanced.Accuracy<-data.matrix(CHL_RF_AccStats[,"Balanced Accuracy"])     
View(Balanced.Accuracy)
```

| MIC Isolate Category | Balanced Accuracy |
|:---------------------|:------------------|

|               |           |
|--------------:|-----------|
|  **Class: 4** | 0.6513204 |
|  **Class: 8** | 0.6368492 |
| **Class: 16** | 0.5000000 |
| **Class: 32** | 0.7899765 |

##### Plus or Minus One Accuracy:

```{r}
PlusorMinus1_ConMat_Accuracy(CHL_RF_ConMat)
```

| **MIC isolate category** | **Proportion_of_Isolates** |
|:-------------------------|:---------------------------|

|     |           |
|-----|-----------|
| 4   | 0.9924242 |
| 8   | 0.9899229 |
| 16  | 0.8269231 |
| 32  | 0.5890411 |

```{r}
PlusorMinus1_overall(CHL_RF_ConMat)
```

##### NARMS Breakpoint Classification Accuracy:

```{r}
BreakpointClassificationAccuracy(CHL_RF_ConMat, 8)
```

##### ECOFF Breakpoint Classification Accuracy:

```{r}
BreakpointClassificationAccuracy(CHL_RF_ConMat, 16)
```

##### Major and Minor Error

```{r}
MajorandMinorError(CHL_RF_ConMat, 8)
```

### Oversampling to Balance All Categories

##### Build RF using Training Data:

```{r}
set.seed(71)   
RFCHL<-randomForest(CHL~Year+SOURCE+AMC+AXO+CIP+COT+FOX+GEN+NAL+TET+AMP+FIS, data=over.CHL.RF.df, na.action=na.exclude, ntree=500, importance=TRUE)   
RFCHL   
#22.16% OOB estimate of error rate   
#ntree=500   
#mtry=3 (number of variables tried at each split)  
```

##### Tune Predictor Variables:

```{r}
##check the order of the predictors in the model's prediction power  
pre.or <- sort(RFCHL$importance[,3], decreasing = TRUE) #adding [,3] gives the power with the title of the variable 
pre.or   
remove(pre.or)    
#return a plot showing the importance of a predictor to the model by accuracy and Gini score   
varImpPlot(RFCHL, main="")
```

-   Strongest predictors

    -   Year

    -   sulfisoxazole (folate pathway inhibitor)

##### Prediction on Training Data

```{r}
trainRFCHL_prediction<- predict(RFCHL,over.CHL.RF.df)    
trainconMatCHLRF<-confusionMatrix(trainRFCHL_prediction, over.CHL.RF.df$CHL) 
trainconMatCHLRF$table   
paste('Accuracy =', round(trainconMatCHLRF$overall["Accuracy"],2)) #returns accuracy 
trainconMatCHLRF$overall #also gives accuracy in output in scientific notation   
#accuracy is now 83% on training data
```

##### Prediction on Test Data:

```{r}
testRFCHL_prediction<-predict(RFCHL,testCHLRF)  
testConMatCHLRF<-confusionMatrix(testRFCHL_prediction,testCHLRF$CHL)  
paste('Accuracy =', round(testConMatCHLRF$overall["Accuracy"],2)) #returns accuracy 
#accuracy is 57% on test data    
CHL_RF_ConMat<-testConMatCHLRF$table  #saves just the confusion matrix as an object for future analysis  

testConMatCHLRF
```

##### Exact Accuracy:

```{r}
ConMat_Accuracy(CHL_RF_ConMat)
```

| **MIC isolate category** | **Proportion_of_Isolates** |
|:-------------------------|:---------------------------|

|     |           |
|-----|-----------|
| 4   | 0.6377410 |
| 8   | 0.4961470 |
| 16  | 0.2115385 |
| 32  | 0.8424658 |

##### Balanced Accuracy:

```{r}
CHL_RF_AccStats<-testConMatCHLRF$byClass       
Balanced.Accuracy<-data.matrix(CHL_RF_AccStats[,"Balanced Accuracy"])      
View(Balanced.Accuracy)
```

| MIC Isolate Category | Balanced Accuracy |
|:---------------------|:------------------|

|               |           |
|--------------:|-----------|
|  **Class: 4** | 0.6546795 |
|  **Class: 8** | 0.6177705 |
| **Class: 16** | 0.5689351 |
| **Class: 32** | 0.8978860 |

##### Plus or Minus One Accuracy:

```{r}
PlusorMinus1_ConMat_Accuracy(CHL_RF_ConMat)
```

| **MIC isolate category** | **Proportion_of_Isolates** |
|:-------------------------|:---------------------------|

|     |           |
|-----|-----------|
| 4   | 0.9008264 |
| 8   | 0.9496147 |
| 16  | 0.8653846 |
| 32  | 0.8424658 |

```{r}
PlusorMinus1_overall(CHL_RF_ConMat)
```

##### NARMS Breakpoint Classification Accuracy:

```{r}
BreakpointClassificationAccuracy(CHL_RF_ConMat, 8)
```

##### ECOFF Breakpoint Classification Accuracy:

```{r}
BreakpointClassificationAccuracy(CHL_RF_ConMat, 16)
```

##### Major and Minor Error

```{r}
MajorandMinorError(CHL_RF_ConMat, 16)
```

### BEST MODEL: Mix of oversampling and undersampling

##### Build RF using Training Data:

```{r}
set.seed(71)    
final_RFCHL<-randomForest(CHL~Year+AMC+AXO+CIP+COT+FOX+GEN+NAL+TET+AMP+FIS, data=under_over.CHL.RF.df, na.action=na.exclude, ntree=500, importance=TRUE)    
final_RFCHL    
#33% OOB estimate of error rate   
#ntree=500    
#mtry=3 (number of variables tried at each split)  
```

##### Tune Predictor Variables:

```{r}
##check the order of the predictors in the model's prediction power   
pre.or <- sort(final_RFCHL$importance[,3], decreasing = TRUE) #adding [,3] gives the power with the title of the variable  
pre.or    
remove(pre.or)     

#return a plot showing the importance of a predictor to the model by accuracy and Gini score    
varImpPlot(final_RFCHL, main="")
```

-   Strongest predictors

    -   Sulfisoxazole (folate pathway inhibitor)

    -   nalidixic acid (quinolone)

##### Prediction on Training Data

```{r}
set.seed(71)
final_trainRFCHL_prediction<- predict(final_RFCHL,under_over.CHL.RF.df)     
final_trainconMatCHLRF<-confusionMatrix(final_trainRFCHL_prediction, under_over.CHL.RF.df$CHL)
final_trainconMatCHLRF$table    
paste('Accuracy =', round(final_trainconMatCHLRF$overall["Accuracy"],2)) #returns accuracy  
final_trainconMatCHLRF$overall #also gives accuracy in output in scientific notation   
#accuracy is now 85% on training data
```

##### Prediction on Test Data:

```{r}
set.seed(71)
final_testRFCHL_prediction<-predict(final_RFCHL,testCHLRF)   
final_testConMatCHLRF<-confusionMatrix(final_testRFCHL_prediction,testCHLRF$CHL)   
paste('Accuracy =', round(final_testConMatCHLRF$overall["Accuracy"],2)) #returns accuracy 
#accuracy is 52% on test data 

final_CHL_RF_ConMat<-final_testConMatCHLRF$table  #saves just the confusion matrix as an object for future analysis    

final_testConMatCHLRF
```

##### Exact Accuracy:

```{r}
ConMat_Accuracy(final_CHL_RF_ConMat)
```

| **MIC isolate category** | **Proportion_of_Isolates** |
|:-------------------------|:---------------------------|

|     |           |
|-----|-----------|
| 4   | 0.6990358 |
| 8   | 0.3432128 |
| 16  | 0.3269231 |
| 32  | 0.9246575 |

##### Balanced Accuracy:

```{r}
CHL_RF_AccStats<-final_testConMatCHLRF$byClass        
Balanced.Accuracy<-data.matrix(CHL_RF_AccStats[,"Balanced Accuracy"])       
View(Balanced.Accuracy)
```

| MIC Isolate Category | Balanced Accuracy |
|:---------------------|:------------------|

|               |           |
|--------------:|-----------|
|  **Class: 4** | 0.6399688 |
|  **Class: 8** | 0.5806973 |
| **Class: 16** | 0.6211480 |
| **Class: 32** | 0.9273867 |

##### Plus or Minus One Accuracy by Category:

```{r}
PlusorMinus1_ConMat_Accuracy(final_CHL_RF_ConMat)
```

| **MIC isolate category** | **Proportion_of_Isolates** |
|:-------------------------|:---------------------------|

|     |           |
|-----|-----------|
| 4   | 0.8891185 |
| 8   | 0.9223474 |
| 16  | 0.8076923 |
| 32  | 0.9315068 |

##### Plus or Minus One Accuracy Overall:

```{r}
PlusorMinus1_overall(final_CHL_RF_ConMat)
```

##### NARMS Breakpoint Classification Accuracy:

```{r}
BreakpointClassificationAccuracy(final_CHL_RF_ConMat, 8)
```

##### ECOFF Breakpoint Classification Accuracy:

```{r}
BreakpointClassificationAccuracy(final_CHL_RF_ConMat, 16)
```

##### Major and Minor Error

```{r}
MajorandMinorError(final_CHL_RF_ConMat, 8)
```

```{r}
remove(RFCHL, trainconMatCHLRF, trainRFCHL_prediction, testRFCHL_prediction, testConMatCHLRF, CHL_RF_ConMat, C.perc, CHL_RF_AccStats, Balanced.Accuracy )

remove(over.CHL.RF.df, under_over.CHL.RF.df, final_trainconMatCHLRF, final_trainRFCHL_prediction, trainCHLRF_labels)
```
