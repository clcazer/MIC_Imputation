# Ciprofloxacin (CIP)

-   CLSI Class: Quinolones

## Filtering CIP isolates

##### Filtering CIP isolates into a separate dataframe to build RF

```{r}
CIP.RF.df <- NARMSCattleCombined_ordinal   
#checking if there are any NAs for this variable in this dataframe 
(sum(is.na(CIP.RF.df[40]))/nrow(CIP.RF.df)*100) #returns 0 
```

##### Check dependent variable (what predicting) is a factor in dataframe

```{r}
is.factor(CIP.RF.df$CIP) #returns TRUE 
```

##### Make all categorical variables in dataframe factors

```{r}
CategoricalVar<-c("STATE", "Year", "Month", "RAISING_CLAIM", "COUNTRY_OF_ORIGIN", "SOURCE", "SOURCE_SPECIES_INFO", "BRAND", "BRAND_NAME", "dataset_source", "HOST_SPECIES") 

CIP.RF.df[CategoricalVar]<-lapply(CIP.RF.df[CategoricalVar], factor)

remove(CategoricalVar) 
#Resist.Genes variables (ex: Aminoglycoside.Resist.Genes), GENOTYPE were not included in model because majority of isolates do not have this information
```

## Missing Data Analysis for Antimicrobials

##### For each AM, what percentage of total number of isolates were tested against that AM

```{r}
MissingDataAnalysis_AMs(CIP.RF.df)
```

| **AM_Name** | **Percent_of_Isolates_Tested** |
|:------------|:-------------------------------|

|         |                  |
|---------|------------------|
| **AMC** | **100.00000000** |
| **AXO** | **100.00000000** |
| **CHL** | **100.00000000** |
| CIP     | 100.00000000     |
| **COT** | **100.00000000** |
| **FOX** | **100.00000000** |
| **GEN** | **100.00000000** |
| **NAL** | **100.00000000** |
| **TET** | **100.00000000** |
| **AMP** | **99.99146248**  |
| Str     | 99.98292496      |
| **FIS** | **94.86894903**  |
| AZI     | 78.04149236      |
| MER     | 51.72031077      |
| TIO     | 48.27968923      |
| KAN     | 32.20353453      |
| AMI     | 21.95850764      |
| CEP     | 5.13105097       |
| SMX     | 5.13105097       |
| ATM     | 0.05122513       |
| CAZ     | 0.05122513       |
| CTX     | 0.05122513       |
| FEP     | 0.05122513       |
| IMI     | 0.05122513       |
| PTZ     | 0.05122513       |
| APR     | 0.00000000       |
| CLI     | 0.00000000       |
| DAP     | 0.00000000       |
| DOX     | 0.00000000       |
| ERY     | 0.00000000       |
| FFN     | 0.00000000       |
| LIN     | 0.00000000       |
| LZD     | 0.00000000       |
| NIT     | 0.00000000       |
| PEN     | 0.00000000       |
| QDA     | 0.00000000       |
| TEL     | 0.00000000       |
| TGC     | 0.00000000       |
| TYL     | 0.00000000       |
| VAN     | 0.00000000       |

10 AM predictors are measured on 90% or greater of the isolates in the dataframe (not including Str because of protocol change in MIC measurement) and so will be used as possible predictor variables

## Missing Data Analysis for Categorical Variables

##### For each categorical variable, what percentage of total number of isolates were tested against that variable

```{r}
MissingDataAnalysis_CategoricalVar(CIP.RF.df)
```

| **Variable Name** | **Percent_of_Isolates_Tested** |
|:------------------|:-------------------------------|

|                     |                |
|---------------------|----------------|
| **Year**            | **100.000000** |
| **dataset_source**  | **100.000000** |
| **SOURCE**          | **100.000000** |
| **HOST_SPECIES**    | **100.000000** |
| ACQUISITION_DATE    | 99.846325      |
| Month               | 88.201144      |
| SOURCE_SPECIES_INFO | 77.332878      |
| STATE               | 39.084778      |
| GROWTH              | 39.084778      |
| MEAT_TYPE           | 39.084778      |
| BRAND_NAME          | 36.062495      |
| BRAND               | 35.652694      |
| CUTS                | 20.037565      |
| COUNTRY_OF_ORIGIN   | 11.585418      |
| GENOTYPE            | 9.997439       |
| RAISING_CLAIM       | 4.482199       |

##### Checking Levels for Categorical Variables with 90% plus data:

```{r}
levels(CIP.RF.df$Year)
```

```{r}
levels(CIP.RF.df$dataset_source)
```

```{r}
levels(CIP.RF.df$SOURCE)
```

```{r}
levels(CIP.RF.df$HOST_SPECIES)
```

Possible Categorical Variable Predictor Variables: (have enough data filled in and have unique levels)

-   SOURCE

-   Year

## Create 70% Training and 30% Testing Data Split

```{r}
#set a random seed and shuffle data frame to get random sample of data in both the testing and training set  
set.seed(1234)  
CIP.RF.df<-CIP.RF.df[sample(1:nrow(CIP.RF.df)), ]
```

```{r}
#use 70% data for training and other 30% for testing   
# get the number 70/30 training test split  
numberOfTrainingSamples <- round(length(CIP.RF.df$CIP) * .7)   

# training data  
set.seed(1234)  
trainCIPRF <- CIP.RF.df[1:numberOfTrainingSamples,] 
trainCIPRF_labels <- CIP.RF.df$CIP[1:numberOfTrainingSamples]    

# testing data  
set.seed(1234)  
testCIPRF <- CIP.RF.df[-(1:numberOfTrainingSamples),]  
testCIPRF_labels <- CIP.RF.df$CIP[-(1:numberOfTrainingSamples)] 

remove(numberOfTrainingSamples)
```

## Balancing CIP Levels:

##### Original Training Data distribution:

```{r}
table(trainCIPRF$CIP)
```

##### Try undersampling just the majority class:

```{r}
#Undersample just MIC 0.015 to make it more even 
set.seed(71)
C.perc= list("0.015"=0.02)
under.CIP.RF.df<- RandUnderClassif(CIP~., trainCIPRF, C.perc)  

table(under.CIP.RF.df$CIP) #correctly undersampled MIC 0.015 values to only have 0.04*7993= 319
```

##### Try oversampling to balance all categories

```{r}
#Oversample to balance all MIC categories 
set.seed(71)
over.CIP.RF.df<- RandOverClassif(CIP~., trainCIPRF, "balance") 
#"balance" tries to balance all existing classes  

table(over.CIP.RF.df$CIP) #This oversamples other categories so that there are 7993 rows (number of observations of majority category) for each
```

## Random Forest:

### Original:

##### Build RF using Training Data:

```{r}
set.seed(71) 
RFCIP<-randomForest(CIP~Year+SOURCE+AMC+AXO+CHL+COT+FOX+GEN+NAL+TET+AMP+FIS, data=trainCIPRF, na.action=na.exclude, ntree=500, importance=TRUE) 
RFCIP 
#2% OOB estimate of error rate 
#ntree=500
#mtry=3 (number of variables tried at each split) 

```

##### Tune Predictor Variables:

```{r}
##check the order of the predictors in the model's prediction power 
pre.or <- sort(RFCIP$importance[,3], decreasing = TRUE) #adding [,3] gives the power with the title of the variable 
pre.or 
remove(pre.or) 
#return a plot showing the importance of a predictor to the model by accuracy and Gini score 
varImpPlot(RFCIP, main="")
```

-   Strongest predictors

    -   Nalidixic Acid (another quinolone!)

##### Prediction on Training Data

```{r}
set.seed(71)
trainRFCIP_prediction<- predict(RFCIP,trainCIPRF)  
trainconMatCIPRF<-confusionMatrix(trainRFCIP_prediction, trainCIPRF$CIP)
trainconMatCIPRF$table  
paste('Accuracy =', round(trainconMatCIPRF$overall["Accuracy"],2)) #returns accuracy  
trainconMatCIPRF$overall #also gives accuracy in output in scientific notation  #accuracy is now 99% on training data!
```

##### Prediction on Test Data:

```{r}
set.seed(71)
testRFCIP_prediction<-predict(RFCIP,testCIPRF)  
testConMatCIPRF<-confusionMatrix(testRFCIP_prediction,testCIPRF$CIP)
paste('Accuracy =', round(testConMatCIPRF$overall["Accuracy"],2)) #returns accuracy #accuracy is 99% on test data

CIP_RF_ConMat<-testConMatCIPRF$table #saves just the confusion matrix as an object for future analysis  

testConMatCIPRF
```

##### Exact Accuracy:

```{r}
ConMat_Accuracy(CIP_RF_ConMat)
```

| **MIC isolate category** | **Proportion_of_Isolates** |
|:-------------------------|:---------------------------|

|       |           |
|-------|-----------|
| 0.015 | 0.9990800 |
| 0.06  | 0.0000000 |
| 0.125 | 0.8372093 |

##### Balanced Accuracy:

```{r}
CIP_RF_AccStats<-testConMatCIPRF$byClass   
Balanced.Accuracy<-data.matrix(CIP_RF_AccStats[,"Balanced Accuracy"])  
View(Balanced.Accuracy)
```

| MIC Isolate Category | Balanced Accuracy |
|:---------------------|:------------------|

|                  |           |
|-----------------:|-----------|
| **Class: 0.015** | 0.7495400 |
|  **Class: 0.06** | 0.4998487 |
| **Class: 0.125** | 0.9179975 |

##### Plus or Minus One Accuracy:

```{r}
PlusorMinus1_ConMat_Accuracy(CIP_RF_ConMat)
```

| **MIC isolate category** | **Proportion_of_Isolates** |
|:-------------------------|:---------------------------|

|       |           |
|-------|-----------|
| 0.015 | 0.9993867 |
| 0.06  | 1.0000000 |
| 0.125 | 0.8372093 |

```{r}
PlusorMinus1_overall(CIP_RF_ConMat)
```

##### NARMS Breakpoint Classification Accuracy:

```{r}
BreakpointClassificationAccuracy(CIP_RF_ConMat, 0.06)
```

##### ECOFF Breakpoint Classification Accuracy:

```{r}
BreakpointClassificationAccuracy(CIP_RF_ConMat, 0.06)
```

##### Major and Minor Error

```{r}
MajorandMinorError(CIP_RF_ConMat, 0.06)
```

### Oversampling to Balance All Categories

##### Build RF using Oversampled Training Data:

```{r}
set.seed(71)    
RFCIP<-randomForest(CIP~Year+SOURCE+AMC+AXO+CHL+COT+FOX+GEN+NAL+TET+AMP+FIS, data=over.CIP.RF.df, na.action=na.exclude, ntree=500, importance=TRUE)    
RFCIP   
#1% OOB estimate of error rate   
#ntree=500  
#mtry=3 (number of variables tried at each split)   
```

##### Tune Predictor Variables:

```{r}
##check the order of the predictors in the model's prediction power 
pre.or <- sort(RFCIP$importance[,3], decreasing = TRUE) #adding [,3] gives the power with the title of the variable    
pre.or    
remove(pre.or)      
#return a plot showing the importance of a predictor to the model by accuracy and Gini score    
varImpPlot(RFCIP, main="")
```

-   Strongest predictors

    -   Nalidixic Acid (another quinolone!)

##### Prediction on Training Data

```{r}
set.seed(71)
trainRFCIP_prediction<- predict(RFCIP,over.CIP.RF.df)     
trainconMatCIPRF<-confusionMatrix(trainRFCIP_prediction, over.CIP.RF.df$CIP) 
trainconMatCIPRF$table     
paste('Accuracy =', round(trainconMatCIPRF$overall["Accuracy"],2)) #returns accuracy  
trainconMatCIPRF$overall #also gives accuracy in output in scientific notation  
#accuracy is now 99% on training data
```

##### Prediction on Test Data:

```{r}
set.seed(71)
testRFCIP_prediction<-predict(RFCIP,testCIPRF)     
testConMatCIPRF<-confusionMatrix(testRFCIP_prediction,testCIPRF$CIP)  
paste('Accuracy =', round(testConMatCIPRF$overall["Accuracy"],2))
#returns accuracy  
#accuracy is 96% on test data      
CIP_RF_ConMat<-testConMatCIPRF$table #saves just the confusion matrix as an object for future analysis     
CIP_RF_ConMat
```

##### Exact Accuracy:

```{r}
ConMat_Accuracy(CIP_RF_ConMat)
```

| **MIC isolate category** | **Proportion_of_Isolates** |
|:-------------------------|:---------------------------|

|       |            |
|-------|------------|
| 0.015 | 0.97301441 |
| 0.06  | 0.09090909 |
| 0.125 | 0.83720930 |

##### Plus or Minus One Accuracy:

```{r}
PlusorMinus1_ConMat_Accuracy(CIP_RF_ConMat)
```

| **MIC isolate category** | **Proportion_of_Isolates** |
|:-------------------------|:---------------------------|

|       |           |
|-------|-----------|
| 0.015 | 0.9969335 |
| 0.06  | 1.0000000 |
| 0.125 | 0.8372093 |

```{r}
PlusorMinus1_overall(CIP_RF_ConMat)
```

##### NARMS Breakpoint Classification Accuracy:

```{r}
BreakpointClassificationAccuracy(CIP_RF_ConMat, 0.06)
```

##### ECOFF Breakpoint Classification Accuracy:

```{r}
BreakpointClassificationAccuracy(CIP_RF_ConMat, 0.06)
```

##### Major and Minor Error

```{r}
MajorandMinorError(CIP_RF_ConMat, 0.06)
```

### BEST MODEL: Undersampling MIC 0.015

##### Build RF using Undersampled Training Data:

```{r}
set.seed(71)  
final_RFCIP<-randomForest(CIP~Year+AMC+AXO+CHL+COT+FOX+GEN+NAL+TET+AMP+FIS, data=under.CIP.RF.df, na.action=na.exclude, ntree=500, importance=TRUE)  
final_RFCIP  
#20.92% OOB estimate of error rate  
#ntree=500
#mtry=3 (number of variables tried at each split)  
```

##### Tune Predictor Variables:

```{r}
##check the order of the predictors in the model's prediction power  
pre.or <- sort(final_RFCIP$importance[,3], decreasing = TRUE) #adding [,3] gives the power with the title of the variable  
pre.or  
remove(pre.or)  

#return a plot showing the importance of a predictor to the model by accuracy and Gini score  
varImpPlot(final_RFCIP, main="")
```

-   Strongest predictors

    -   Nalidixic Acid (another quinolone!)

##### Prediction on Training Data

```{r}
set.seed(71)
final_trainRFCIP_prediction<- predict(final_RFCIP,under.CIP.RF.df)   
final_trainconMatCIPRF<-confusionMatrix(final_trainRFCIP_prediction, under.CIP.RF.df$CIP)
final_trainconMatCIPRF$table   
paste('Accuracy =', round(final_trainconMatCIPRF$overall["Accuracy"],2)) #returns accuracy  
final_trainconMatCIPRF$overall #also gives accuracy in output in scientific notation  #accuracy is now 97% on training data
```

##### Prediction on Test Data:

```{r}
set.seed(71)
final_testRFCIP_prediction<-predict(final_RFCIP,testCIPRF)   
final_testConMatCIPRF<-confusionMatrix(final_testRFCIP_prediction,testCIPRF$CIP) 
paste('Accuracy =', round(final_testConMatCIPRF$overall["Accuracy"],2)) 
#returns accuracy #accuracy is 84% on test data  

final_CIP_RF_ConMat<-final_testConMatCIPRF$table #saves just the confusion matrix as an object for future analysis   

final_testConMatCIPRF
```

##### Exact Accuracy:

```{r}
ConMat_Accuracy(final_CIP_RF_ConMat)
```

| **MIC isolate category** | **Proportion_of_Isolates** |
|:-------------------------|:---------------------------|

|       |           |
|-------|-----------|
| 0.015 | 0.8442196 |
| 0.06  | 0.6060606 |
| 0.125 | 0.9069767 |

##### Balanced Accuracy:

```{r}
CIP_RF_AccStats<-final_testConMatCIPRF$byClass    
Balanced.Accuracy<-data.matrix(CIP_RF_AccStats[,"Balanced Accuracy"])   
View(Balanced.Accuracy)
```

| MIC Isolate Category | Balanced Accuracy |
|:---------------------|:------------------|

|                  |           |
|-----------------:|-----------|
| **Class: 0.015** | 0.8365835 |
|  **Class: 0.06** | 0.7302397 |
| **Class: 0.125** | 0.9487828 |

##### Plus or Minus One Accuracy by Category:

```{r}
PlusorMinus1_ConMat_Accuracy(final_CIP_RF_ConMat)
```

| **MIC isolate category** | **Proportion_of_Isolates** |
|:-------------------------|:---------------------------|

|       |           |
|-------|-----------|
| 0.015 | 0.9914137 |
| 0.06  | 1.0000000 |
| 0.125 | 0.9302326 |

##### Plus or Minus One Accuracy Overall:

```{r}
PlusorMinus1_overall(final_CIP_RF_ConMat)
```

##### NARMS Breakpoint Classification Accuracy:

```{r}
BreakpointClassificationAccuracy(final_CIP_RF_ConMat, 0.06)
```

##### ECOFF Breakpoint Classification Accuracy:

```{r}
BreakpointClassificationAccuracy(final_CIP_RF_ConMat, 0.06)
```

##### Major and Minor Error

```{r}
MajorandMinorError(final_CIP_RF_ConMat, 0.06)
```

```{r}
remove(RFCIP, trainconMatCIPRF, trainRFCIP_prediction, testRFCIP_prediction, testConMatCIPRF, CIP_RF_ConMat, C.perc, CIP_RF_AccStats, Balanced.Accuracy )

remove(over.CIP.RF.df, final_trainconMatCIPRF, final_trainRFCIP_prediction, trainCIPRF_labels)
```
