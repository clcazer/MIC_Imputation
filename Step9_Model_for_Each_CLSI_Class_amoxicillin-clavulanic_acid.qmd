---
title: "Model_for_Each_CLSI_Class_AMC"
format: html
editor: visual
---

# Amoxicillin-clavulanic acid (AMC)

-   CLSI Class: B-lactam combination agents

    ## Filtering AMC isolates

    ##### Filtering AMC isolates into a separate dataframe to build RF

    ```{r}
    AMC.RF.df <- NARMSCattleCombined_ordinal

    #checking if there are any NAs for AMC variable in this dataframe  
    (sum(is.na(AMC.RF.df[match("AMC",names(NARMSCattleCombined_ordinal))]))/nrow(AMC.RF.df)*100) #match command returns the column number with the name AMC
    #returns 0%  
    ```

    ##### Check dependent variable (what predicting) is a factor in dataframe

    ```{r}
    is.factor(AMC.RF.df$AMC) #returns true
    ```

    ##### Make all categorical variables in dataframe factors

    ```{r}
    CategoricalVar<-c("STATE", "Year", "Month", "RAISING_CLAIM", "COUNTRY_OF_ORIGIN", "SOURCE", "SOURCE_SPECIES_INFO", "BRAND", "BRAND_NAME", "dataset_source", "MEAT_TYPE", "HOST_SPECIES")  

    AMC.RF.df[CategoricalVar]<-lapply(AMC.RF.df[CategoricalVar], factor) 

    remove(CategoricalVar)  
    #Resist.Genes variables (ex: Aminoglycoside.Resist.Genes), GENOTYPE were not included in model because majority of isolates do not have this information 
    ```

    ## Missing Data Analysis for Antimicrobials

    ##### For each AM, what percentage of total number of isolates were tested against that AM

    ```{r}
    MissingDataAnalysis_AMs(AMC.RF.df)
    ```

|         |                  |
|---------|------------------|
| AMC     | 100.00000000     |
| **AXO** | **100.00000000** |
| **CHL** | **100.00000000** |
| **CIP** | **100.00000000** |
| **COT** | **100.00000000** |
| **FOX** | **100.00000000** |
| **GEN** | **100.00000000** |
| **NAL** | **100.00000000** |
| **TET** | **100.00000000** |
| **AMP** | **99.99146248**  |
| Str     | 99.98292496      |
| **FIS** | **94.86894903**  |
| AZI     | 78.04149236      |
| MER     | 51.72031077      |
| TIO     | 48.27968923      |
| KAN     | 32.20353453      |
| AMI     | 21.95850764      |
| CEP     | 5.13105097       |
| SMX     | 5.13105097       |
| ATM     | 0.05122513       |
| CAZ     | 0.05122513       |
| CTX     | 0.05122513       |
| FEP     | 0.05122513       |
| IMI     | 0.05122513       |
| PTZ     | 0.05122513       |
| APR     | 0.00000000       |
| CLI     | 0.00000000       |
| DAP     | 0.00000000       |
| DOX     | 0.00000000       |
| ERY     | 0.00000000       |
| FFN     | 0.00000000       |
| LIN     | 0.00000000       |
| LZD     | 0.00000000       |
| NIT     | 0.00000000       |
| PEN     | 0.00000000       |
| QDA     | 0.00000000       |
| TEL     | 0.00000000       |
| TGC     | 0.00000000       |
| TYL     | 0.00000000       |
| VAN     | 0.00000000       |

10 predictor variables tested on \>90% isolates (not including Str because of protocol change in MIC measurement) and so can be used in model

## Missing Data Analysis for Categorical Variables

##### For each categorical variable, what percentage of total number of isolates were tested against that variable

```{r}
MissingDataAnalysis_CategoricalVar(AMC.RF.df)
```

| **Variable Name** | **Percent_of_Isolates_Tested** |
|:------------------|:-------------------------------|

|                     |                |
|---------------------|----------------|
| **Year**            | **100.000000** |
| **dataset_source**  | **100.000000** |
| **SOURCE**          | **100.000000** |
| **HOST_SPECIES**    | **100.000000** |
| ACQUISITION_DATE    | 99.846325      |
| Month               | 88.201144      |
| SOURCE_SPECIES_INFO | 77.332878      |
| STATE               | 39.084778      |
| GROWTH              | 39.084778      |
| MEAT_TYPE           | 39.084778      |
| BRAND_NAME          | 36.062495      |
| BRAND               | 35.652694      |
| CUTS                | 20.037565      |
| COUNTRY_OF_ORIGIN   | 11.585418      |
| GENOTYPE            | 9.997439       |
| RAISING_CLAIM       | 4.482199       |

##### Checking Levels for Categorical Variables with 90% plus data:

```{r}
levels(AMC.RF.df$Year)
```

```{r}
levels(AMC.RF.df$dataset_source)
```

```{r}
levels(AMC.RF.df$SOURCE)
```

```{r}
levels(AMC.RF.df$HOST_SPECIES)
```

Possible Categorical Variable Predictor Variables: (have enough data filled in and have unique levels)

-   Year
-   SOURCE

## Create 70% Training 30% Testing Split

```{r}
#set a random seed and shuffle data frame to get random sample of data in both the testing and training set   
set.seed(1234)   
AMC.RF.df<-AMC.RF.df[sample(1:nrow(AMC.RF.df)), ]
```

```{r}
#use 70% data for training and other 30% for testing

# get the number 70/30 training test split   
numberOfTrainingSamples <- round(length(AMC.RF.df$AMC) * .7) 

# training data   
set.seed(1234)   
trainAMCRF <- AMC.RF.df[1:numberOfTrainingSamples,]  
trainAMCRF_labels <- AMC.RF.df$AMC[1:numberOfTrainingSamples]

# testing data  
set.seed(1234)  
testAMCRF <- AMC.RF.df[-(1:numberOfTrainingSamples),]   
testAMCRF_labels <-AMC.RF.df$AMC[-(1:numberOfTrainingSamples)]

remove(numberOfTrainingSamples)
```

## Balancing AMC Levels

##### Look at original training data distribution

```{r}
table(trainAMCRF$AMC)
```

##### Try oversampling

```{r}
#Oversample to balance all MIC categories  
set.seed(71)
over.AMC.RF.df<- RandOverClassif(AMC~., trainAMCRF, "balance")  #"balance" tries to balance all existing classes    

table(over.AMC.RF.df$AMC) #This oversamples other categories so that there are 5045 rows (number of observations of majority category) for each
```

##### Try a mix of undersampling and oversampling

```{r}
#Undersample MIC category 4 and 2
set.seed(71)
C.perc= list("4"=0.2, "2"=0.6)  
under_over.AMC.RF.df<- RandUnderClassif(AMC~., trainAMCRF, C.perc)   
table(under_over.AMC.RF.df$AMC) #first undersample  

#Oversample MIC category 1, 16, 32  
set.seed(71)
C.perc= list("1"=2.3, "16"=35, "32"= 10 )  
under_over.AMC.RF.df<- RandOverClassif(AMC~., under_over.AMC.RF.df, C.perc)   
table(under_over.AMC.RF.df$AMC) #then oversample
```

## Random Forest:

### Original

##### Build RF using Training Data:

```{r}
set.seed(71)  
RFAMC<-randomForest(AMC~Year+SOURCE+AXO+AMP+CHL+CIP+COT+FIS+FOX+GEN+NAL+TET, data=trainAMCRF, na.action=na.exclude, ntree=500, importance=TRUE)  
RFAMC
#28.96% OOB estimate of error rate  
#ntree=500  
#mtry=3 (number of variables tried at each split)  
```

##### Tune Predictor Variables

```{r}
##check the order of the predictors in the model's prediction power  
pre.or <- sort(RFAMC$importance[,3], decreasing = TRUE) #adding [,3] gives the power with the title of the variable 
pre.or  
remove(pre.or)   
#return a plot showing the importance of a predictor to the model by accuracy and Gini score  
varImpPlot(RFAMC, main="")
```

-   Strongest predictors

    -   AMPICILLIN (another B lactam)

##### Prediction on Training Data

```{r}
set.seed(71)
trainRFAMC_prediction<- predict(RFAMC,trainAMCRF)   
trainconMatAMCRF<-confusionMatrix(trainRFAMC_prediction, trainAMCRF$AMC)
trainconMatAMCRF$table  
paste('Accuracy =', round(trainconMatAMCRF$overall["Accuracy"],2)) #returns accuracy
trainconMatAMCRF$overall #also gives accuracy in output in scientific notation   #accuracy is now 80% on training data
```

##### Prediction on Test Data:

```{r}
set.seed(71)
testRFAMC_prediction<-predict(RFAMC,testAMCRF) 
testConMatAMCRF<-confusionMatrix(testRFAMC_prediction,testAMCRF$AMC) 
paste('Accuracy =', round(testConMatAMCRF$overall["Accuracy"],2)) #returns accuracy #accuracy is 71% on test data   

AMC_RF_ConMat<-testConMatAMCRF$table  #saves just the confusion matrix as an object for future analysis 
        
testConMatAMCRF
```

##### Exact Accuracy:

```{r}
ConMat_Accuracy(AMC_RF_ConMat)
```

| **MIC isolate category** | **Proportion_of_Isolates** |
|:-------------------------|:---------------------------|

|     |           |
|-----|-----------|
| 1   | 0.3333333 |
| 2   | 0.3560501 |
| 4   | 0.9361386 |
| 8   | 0.3698980 |
| 16  | 0.1666667 |
| 32  | 0.9062500 |

##### Balanced Accuracy:

```{r}
AMC_RF_AccStats<-testConMatAMCRF$byClass      
Balanced.Accuracy<-data.matrix(AMC_RF_AccStats[,"Balanced Accuracy"])     
View(Balanced.Accuracy)
```

| MIC Isolate Category | Balanced Accuracy |
|:---------------------|:------------------|

|               |           |
|--------------:|-----------|
|  **Class: 1** | 0.6600400 |
|  **Class: 2** | 0.6428837 |
|  **Class: 4** | 0.7023138 |
|  **Class: 8** | 0.6795160 |
| **Class: 16** | 0.5833333 |
| **Class: 32** | 0.9529737 |

##### Plus or Minus One Accuracy:

```{r}
PlusorMinus1_ConMat_Accuracy(AMC_RF_ConMat)
```

| **MIC isolate category** | **Proportion_of_Isolates** |
|:-------------------------|:---------------------------|

|     |           |
|-----|-----------|
| 1   | 0.8273810 |
| 2   | 1.0000000 |
| 4   | 0.9975248 |
| 8   | 0.9923469 |
| 16  | 0.8333333 |
| 32  | 0.9062500 |

```{r}
PlusorMinus1_overall(AMC_RF_ConMat)
```

##### Breakpoint Classification Accuracy:

```{r}
BreakpointClassificationAccuracy(AMC_RF_ConMat, 16)
```

##### Major and Minor Error

```{r}
MajorandMinorError(AMC_RF_ConMat, 16)
```

### Mix of Under and Over

##### Build RF using Training Data:

```{r}
set.seed(71)   
RFAMC<-randomForest(AMC~Year+SOURCE+AXO+AMP+CHL+CIP+COT+FIS+FOX+GEN+NAL+TET, data=under_over.AMC.RF.df, na.action=na.exclude, ntree=500, importance=TRUE)   
RFAMC 
#23.33% OOB estimate of error rate   
#ntree=500   
#mtry=3 (number of variables tried at each split)   
```

##### Tune Predictor Variables

```{r}
##check the order of the predictors in the model's prediction power   
pre.or <- sort(RFAMC$importance[,3], decreasing = TRUE) #adding [,3] gives the power with the title of the variable  
pre.or   
remove(pre.or)    
#return a plot showing the importance of a predictor to the model by accuracy and Gini score   
varImpPlot(RFAMC, main="")
```

-   Strongest predictors

    -   AMPICILLIN (ANOTHER B LACTAM)

##### Prediction on Training Data

```{r}
set.seed(71)
trainRFAMC_prediction<- predict(RFAMC,under_over.AMC.RF.df)    

trainconMatAMCRF<-confusionMatrix(trainRFAMC_prediction, under_over.AMC.RF.df$AMC) 
trainconMatAMCRF$table   
paste('Accuracy =', round(trainconMatAMCRF$overall["Accuracy"],2)) #returns accuracy 
trainconMatAMCRF$overall #also gives accuracy in output in scientific notation   
#accuracy is now 88% on training data
```

##### Prediction on Test Data:

```{r}
set.seed(71)
testRFAMC_prediction<-predict(RFAMC,testAMCRF)  
testConMatAMCRF<-confusionMatrix(testRFAMC_prediction,testAMCRF$AMC)  
paste('Accuracy =', round(testConMatAMCRF$overall["Accuracy"],2)) #returns accuracy  
#accuracy is 49% on test data     
AMC_RF_ConMat<-testConMatAMCRF$table  #saves just the confusion matrix as an object for future analysis   
testConMatAMCRF
```

##### Exact Accuracy:

```{r}
ConMat_Accuracy(AMC_RF_ConMat)
```

| **MIC isolate category** | **Proportion_of_Isolates** |
|:-------------------------|:---------------------------|

|     |           |
|-----|-----------|
| 1   | 0.7380952 |
| 2   | 0.5966620 |
| 4   | 0.3732673 |
| 8   | 0.7551020 |
| 16  | 0.3333333 |
| 32  | 0.9062500 |

##### Balanced Accuracy:

```{r}
AMC_RF_AccStats<-testConMatAMCRF$byClass       
Balanced.Accuracy<-data.matrix(AMC_RF_AccStats[,"Balanced Accuracy"])      
View(Balanced.Accuracy)
```

| MIC Isolate Category | Balanced Accuracy |
|:---------------------|:------------------|

|               |           |
|--------------:|-----------|
|  **Class: 1** | 0.8333897 |
|  **Class: 2** | 0.6612034 |
|  **Class: 4** | 0.6099442 |
|  **Class: 8** | 0.7857004 |
| **Class: 16** | 0.6644151 |
| **Class: 32** | 0.9529737 |

##### Plus or Minus One Accuracy:

```{r}
PlusorMinus1_ConMat_Accuracy(AMC_RF_ConMat)
```

| **MIC isolate category** | **Proportion_of_Isolates** |
|:-------------------------|:---------------------------|

|     |           |
|-----|-----------|
| 1   | 0.9107143 |
| 2   | 0.9902643 |
| 4   | 0.9693069 |
| 8   | 0.9642857 |
| 16  | 0.8333333 |
| 32  | 0.9375000 |

```{r}
PlusorMinus1_overall(AMC_RF_ConMat)
```

##### Breakpoint Classification Accuracy:

```{r}
BreakpointClassificationAccuracy(AMC_RF_ConMat, 16)
```

##### Major and Minor Error

```{r}
MajorandMinorError(AMC_RF_ConMat, 16)
```

### BEST MODEL: Oversampling to balance all categories

##### Build RF using Training Data:

```{r}
set.seed(71)  
final_RFAMC<-randomForest(AMC~Year+AXO+AMP+CHL+CIP+COT+FIS+FOX+GEN+NAL+TET, data=over.AMC.RF.df, na.action=na.exclude, ntree=500, importance=TRUE)  
final_RFAMC
#18% OOB estimate of error rate  
#ntree=500  
#mtry=3 (number of variables tried at each split)
```

##### Tune Predictor Variables

```{r}
##check the order of the predictors in the model's prediction power  
pre.or <- sort(final_RFAMC$importance[,3], decreasing = TRUE) #adding [,3] gives the power with the title of the variable 
pre.or  
remove(pre.or)   
#return a plot showing the importance of a predictor to the model by accuracy and Gini score  
varImpPlot(final_RFAMC, main="")
```

-   Strongest predictors

    -   year

    -   AMPICILLIN (ANOTHER BETA LACTAM)

##### Prediction on Training Data

```{r}
set.seed(71)
final_trainRFAMC_prediction<- predict(final_RFAMC,over.AMC.RF.df)   
final_trainconMatAMCRF<-confusionMatrix(final_trainRFAMC_prediction, over.AMC.RF.df$AMC)
final_trainconMatAMCRF$table  
paste('Accuracy =', round(final_trainconMatAMCRF$overall["Accuracy"],2)) #returns accuracy
final_trainconMatAMCRF$overall #also gives accuracy in output in scientific notation   
#accuracy is now 84% on training data
```

##### Prediction on Test Data:

```{r}
set.seed(71)
final_testRFAMC_prediction<-predict(final_RFAMC,testAMCRF) 
final_testConMatAMCRF<-confusionMatrix(final_testRFAMC_prediction,testAMCRF$AMC) 
paste('Accuracy =', round(final_testConMatAMCRF$overall["Accuracy"],2)) #returns accuracy 
#accuracy is 52% on test data   

final_AMC_RF_ConMat<-final_testConMatAMCRF$table  #saves just the confusion matrix as an object for future analysis 

final_testConMatAMCRF
```

##### Exact Accuracy:

```{r}
ConMat_Accuracy(final_AMC_RF_ConMat)
```

| **MIC isolate category** | **Proportion_of_Isolates** |
|:-------------------------|:---------------------------|

|     |           |
|-----|-----------|
| 1   | 0.7202381 |
| 2   | 0.5688456 |
| 4   | 0.4336634 |
| 8   | 0.7270408 |
| 16  | 0.3333333 |
| 32  | 0.9062500 |

##### Balanced Accuracy:

```{r}
AMC_RF_AccStats<-final_testConMatAMCRF$byClass      
Balanced.Accuracy<-data.matrix(AMC_RF_AccStats[,"Balanced Accuracy"])     
View(Balanced.Accuracy)
```

| MIC Isolate Category | Balanced Accuracy |
|:---------------------|:------------------|

|               |           |
|--------------:|-----------|
|  **Class: 1** | 0.8241456 |
|  **Class: 2** | 0.6492051 |
|  **Class: 4** | 0.6283731 |
|  **Class: 8** | 0.7896664 |
| **Class: 16** | 0.6651656 |
| **Class: 32** | 0.9529737 |

##### Plus or Minus One Accuracy by Category:

```{r}
PlusorMinus1_ConMat_Accuracy(final_AMC_RF_ConMat)
```

| **MIC isolate category** | **Proportion_of_Isolates** |
|:-------------------------|:---------------------------|

|     |           |
|-----|-----------|
| 1   | 0.9285714 |
| 2   | 0.9944367 |
| 4   | 0.9717822 |
| 8   | 0.9668367 |
| 16  | 0.8333333 |
| 32  | 0.9062500 |

##### Plus or Minus One Accuracy Overall:

```{r}
PlusorMinus1_overall(final_AMC_RF_ConMat)
```

##### NARMS Breakpoint Classification Accuracy:

```{r}
BreakpointClassificationAccuracy(final_AMC_RF_ConMat, 16)
```

##### ECOFF Breakpoint Classification Accuracy:

```{r}
BreakpointClassificationAccuracy(final_AMC_RF_ConMat, 8)
```

##### Major and Minor Error

```{r}
MajorandMinorError(final_AMC_RF_ConMat, 16)

```

```{r}
remove(RFAMC, trainconMatAMCRF, trainRFAMC_prediction, testRFAMC_prediction, testConMatAMCRF, AMC_RF_ConMat, C.perc, AMC_RF_AccStats, Balanced.Accuracy )

remove(over.AMC.RF.df, under_over.AMC.RF.df, final_trainconMatAMCRF, final_trainRFAMC_prediction, trainAMCRF_labels)
```
